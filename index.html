<head>
	<title>Application of Riemannian Manifold</title>
</head>
<body>
	<h1 align="center"> Application of Riemannian Manifold </h1>
	<p align="center"> Beijing 101 Middle School: <i>Yuanchenxi Gao</i>
	</p>
	<p align="center"> Shenzhen Yaohua Experimental School: <i>Kongwing Wu</i>
	</p>
	<p align="center"> January 29th, 2023 </p>
	<hr>
	<h2 align="center"> Machine Learning </h2>
	<h3> About </h3>
	<p> Machine learning (ML) is a field of inquiry devoted to understanding and building methods that 'learn', that is, methods that leverage data to improve performance on some set of tasks.
	<p>
	<blockquote style="color:Gray;">
		<p> Mitchell, Tom (1997). <i>Machine Learning</i>. New York: McGraw Hill. </p>
	</blockquote>
	<h3> Brief Description </h3>
	<p> Geometric domain knowledge is important for machine learning systems to interact, process, and generate data from inherently geometric spaces and phenomena. Geometric knowledge typically gives models explicit operations and components that reflect the geometric properties of the domain. An extremely common structure is the Riemannian manifold, a generalization of the standard Euclidean space. These structures allow the model to represent the non-microgeometric properties of the data. </p>
	<p> However, despite this capability, the currently available set of Riemannian manifolds is surprisingly small, and worse, they are often set a priori, as interpolation techniques between manifolds are extremely limited. </p>
	<p> In the following study and research, we will attempt to integrate a general class of Riemannian manifolds into machine learning systems. Specifically, we will build a parametric deep learning system neural network by Riemannian manifolds and optimize the manifolds themselves and their data. </p>
	<blockquote style="color:Gray;">
		<p> Aaron Lou, Maximilian Nickel, Brandon Amos (December 11, 2020). <i>Deep Riemannian Manifold Learning</i>. NeurIPS. </p>
	</blockquote>
	<p> To better fit the geometric structure of the data, recent deep generative modeling techniques adapt the Euclidean structure to non-Euclidean space. Previous work has developed flow models for specific cases. However, these advances have handcrafted layers on a flow-by-flow basis, limiting generality and leading to cumbersome design constraints. </p>
	<p> These problems can be overcome, however, by introducing neural manifold ordinary differential equations, a manifold generalization of neural ODEs that enables the construction of manifold continuous normalized flows (MCNFs.) MCNFs require only local geometry (and thus can be generalized to arbitrary manifolds) and compute probabilities in terms of continuous changes in variables (allowing for simple and expressive flow construction). In turn, the use of continuous manifold dynamics yields significant improvements for both density estimation and downstream tasks. </p>
	<p> In future studies and research, we would also like to see the application of topologically non-microscopic data on continuous normalized flows in lattice quantum field theory, motion estimation and protein structure prediction. </p>
	<blockquote style="color:Gray;">
		<p> Lou, A., Lim, D., Katsman, I., Huang, L., Jiang, Q., Lim, S., & Sa, C.D. (2020). <i>Neural Manifold Ordinary Differential Equations</i>. ArXiv, abs/2006.10254. </p>
	</blockquote>
	<h2 align="center"> Brain-Computer Interfaces </h2>
	<h3> About </h3>
	<p> A brain–computer interface (BCI), sometimes called a brain–machine interface (BMI) or smartbrain, is a direct communication pathway between the brain's electrical activity and an external device, most commonly a computer or robotic limb. BCIs are often directed at researching, mapping, assisting, augmenting, or repairing human cognitive or sensory-motor functions. </p>
	<blockquote style="color:Gray;">
		<p> Krucoff MO, Rahimpour S, Slutzky MW, Edgerton VR, Turner DA (2016). <i>Enhancing Nervous System Recovery through Neurobiologics, Neural Interface Training, and Neurorehabilitation</i>. Frontiers in Neuroscience. 10: 584. doi:10.3389/fnins.2016.00584 </p>
	</blockquote>
	<h3> Brief Description </h3>
	<p> We will study the application of Riemannian manifolds to brain-computer interfaces including feature extraction in motor imagery brain-computer interfaces and Riemannian geometry to decode the pre-processing of motor imagery EEG signals. Since the covariance matrix falls on Riemannian manifolds, Riemannian geometry can be used to model and analyze the second-order statistics of EEG signals, and using Riemannian geometry to analyze and process the covariance matrix has proven to be very effective. Researchers should continue to expand in this direction. </p>
	<p> In practical applications, Riemannian geometry is limited by the problems of overfitting and computational overload due to its high dimensionality, and we combine Riemannian geometry with dimensionality reduction algorithms: firstly, we propose the LIE algorithm for decoding motion imagery EEG signals based on Riemannian geometry. The local information is then integrated using the LLE algorithm to construct global coordinates, and finally a simple linear classifier is used for classification. Since the tangent space Riemannian projection method projects the positive definite symmetric matrix into Euclidean space to obtain vectors of very high dimensionality, Riemannian geometry requires a certain sample size to satisfy the condition that the samples on the Riemann manifold are dense enough to be classified by Riemannian geometry. </p>
	<blockquote style="color:Gray;">
		<p> F. Yger, M. Berar and F. Lotte (2017). <i>Riemannian Approaches in Brain-Computer Interfaces: A Review </i>. IEEE Transactions on Neural Systems and Rehabilitation Engineering, vol. 25, no. 10, pp. 1753-1762. doi: 10.1109/TNSRE.2016.2627016. </p>
		<p> D. Wu, Y. Xu and B. -L. Lu (2022). <i>Transfer Learning for EEG-Based Brain–Computer Interfaces: A Review of Progress Made Since 2016</i>. IEEE Transactions on Cognitive and Developmental Systems, vol. 14, no. 1, pp. 4-19. doi: 10.1109/TCDS.2020.3007453. </p>
	</blockquote>
	<hr>
	<p> Download our PPTX: <a href="kongwingwu.github.io/AXIS/Riemannian_Manifold.pptx">Riemannian_Manifold.pptx</a>; </p>
	<p> Download original paper: <a href="kongwingwu.github.io/AXIS/Fundamental_Theorem_of_the_Local_Theory_of_Curves.pdf">Fundamental_Theorem_of_the_Local_Theory_of_Curves.pdf</a>. </p>
</body>
